{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place du notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de os\n",
    "import os\n",
    "\n",
    "# Importation de pickle\n",
    "import pickle as pk\n",
    "\n",
    "# Importation de la bibliothèque pandas pour la manipulation de données\n",
    "import pandas as pd\n",
    "\n",
    "# Importation des types Dict, List, et Tuple pour une annotation de type plus précise\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Importation de LabelEncoder pour encoder les variables catégoriques\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importation de classification_report pour évaluer les performances du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importation de l'objet variable globale\n",
    "from config import GlobalValue\n",
    "\n",
    "# Ignorer les avertissements spécifiques de la bibliothèque XGBoost\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"xgboost\")\n",
    "\n",
    "# Importation de la bibliothèque XGBoost\n",
    "import xgboost as xgb_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place des variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du fichier contenant des données simulées d'espèces identifiées\n",
    "SIMULATED_FILE: str = \"./datasets/fakes_species_amplicons.csv\"\n",
    "\n",
    "# Chemin du fichier contenant des données simulées d'espèces non identifiées\n",
    "UNIDENTIFIED_FILE: str = \"./datasets/fakes_unidentified_amplicons.csv\"\n",
    "\n",
    "# Seuils spécifiques à chaque espèce pour classer une prédiction comme positive\n",
    "SPECIES_THRESHOLDS: Dict[float, float] = {\n",
    "    0: 0.90,  # Seuil pour Anurofeca_richardsi\n",
    "    1: 0.90,  # Seuil pour Dermocystidium_salmonis\n",
    "    2: 0.90,  # Seuil pour Ichthyophonus_hoferi\n",
    "    3: 0.90,  # Seuil pour Pseudoperkinsus_tapetis\n",
    "    4: 0.90,  # Seuil pour Psorospermium_haeckelii\n",
    "    5: 0.90,  # Seuil pour Rhinosporidium_cygnus\n",
    "    6: 0.90,  # Seuil pour Rhinosporidium_seeberi\n",
    "    7: 0.90,  # Seuil pour Sphaeroforma_spB7\n",
    "    8: 0.90,  # Seuil pour Sphaeroforma_spCRG3\n",
    "    9: 0.90,  # Seuil pour Sphaerothecum_destruens\n",
    "    10: 0.90  # Seuil pour Anurofeca_richardsi\n",
    "}\n",
    "\n",
    "# Listes des barcodes\n",
    "BARCODES: List[int] = list(range(1, 13))\n",
    "\n",
    "# Chemin du dossier contenant les séquences vectorisées\n",
    "DATAS_DIR: str = \"./datasets/Sd_testSet_BC\"\n",
    "\n",
    "# Chemin du dossier qui contiendra les résultats\n",
    "RES_DIR: str = \"./results/\"\n",
    "\n",
    "# Chemin du classifieur\n",
    "CLF_FILE: str = GlobalValue().get_values(\"clf_file\")\n",
    "\n",
    "# Préfixes des fichiers résultats\n",
    "PREFIXES: List[str] = [\"results\", \"probabilities\", \"prediction_distribution\", \"average_class\", \"n_reads_species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions d'analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(data: pd.DataFrame, \n",
    "                        xgb_model: xgb_.XGBClassifier, \n",
    "                        encoder: LabelEncoder) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Analyse les prédictions d'un modèle XGBoost pour un ensemble de données.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Données à utiliser.\n",
    "        xgb_model (XGBClassifier): Modèle XGBoost entraîné.\n",
    "        encoder (LabelEncoder): Objet LabelEncoder ajusté.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]: Les résultats, les probabilités de chaque classe, \n",
    "        la distribution des prédictions, la classe moyenne des reads.\n",
    "    \"\"\"\n",
    "    # Prédire les classes\n",
    "    predictions = xgb_model.predict(X=data)\n",
    "    predictions = encoder.inverse_transform(y=predictions)\n",
    "\n",
    "    # Récupérer les prédictions\n",
    "    results = pd.DataFrame(data={\"prediction\":predictions})\n",
    "\n",
    "    # Récupérer les probabilités de chaque classe, pour chaque reads\n",
    "    probabilities = pd.DataFrame(data=xgb_model.predict_proba(X=data), columns=encoder.classes_)\n",
    "\n",
    "    # Récupérer la distribution des prédictions\n",
    "    prediction_distribution = results[\"prediction\"].value_counts()\n",
    "\n",
    "    # Récupérer la classe moyenne pour l'ensemble des données\n",
    "    average_class = probabilities.mean().sort_values(ascending=False)\n",
    "\n",
    "    # Retourner les résultats\n",
    "    return (results, probabilities, prediction_distribution, average_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_barcode(number: int, xgb_model: xgb_.XGBClassifier, encoder: LabelEncoder) -> None:\n",
    "    \"\"\"\n",
    "    Traite les données d'un barcode en effectuant des prédictions avec le modèle XGBoost.\n",
    "\n",
    "    Args:\n",
    "        number (int): Le numéro du barcode.\n",
    "        xgb_model (XGBClassifier): Le modèle XGBoost entraîné.\n",
    "        encoder (LabelEncoder): L'encodeur utilisé.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Création du barcode\n",
    "    barcode = f\"0{number}\" if number <= 9 else f\"{number}\"\n",
    "\n",
    "    # Création du répertoire résultat si inexistant\n",
    "    if not os.path.exists(path=RES_DIR + f\"barcode{barcode}/\"):\n",
    "        os.makedirs(name=RES_DIR + f\"barcode{barcode}/\")\n",
    "\n",
    "    # Lecture du fichier de données\n",
    "    data_file = pd.read_csv(filepath_or_buffer=DATAS_DIR + f\"{barcode}.csv\")\n",
    "\n",
    "    # Analyse des prédictions avec le modèle XGBoost et l'encodeur\n",
    "    results = analyze_predictions(data=data_file, xgb_model=xgb_model, encoder=encoder)\n",
    "\n",
    "    # Enregistrement des résultats de l'analyse\n",
    "    for prefix, res in zip(PREFIXES[:-1], results):\n",
    "        res.to_csv(path_or_buf=RES_DIR + f\"barcode{barcode}/{prefix}_{barcode}.csv\", index=True)\n",
    "\n",
    "    # Création du dernier fichier\n",
    "    with open(file=RES_DIR + f\"barcode{barcode}/{PREFIXES[-1]}_{barcode}.csv\", mode=\"w\") as tmp:\n",
    "        # Création des headers\n",
    "        tmp.write(\"species,threshold,n_reads_detected\\n\")\n",
    "\n",
    "        # Itération pour chaque espèce\n",
    "        for species_code, threshold in SPECIES_THRESHOLDS.items():\n",
    "            # Calcul du nombre de prédictions au-dessus du seuil\n",
    "            prediction_above_threshold = (threshold <= xgb_model.predict_proba(X=data_file)[:, species_code]).astype(int).sum()\n",
    "\n",
    "            # Conversion du code d'espèce en son nom\n",
    "            species = encoder.inverse_transform(y=[species_code])[0]\n",
    "\n",
    "            # Enregistrement du résultat\n",
    "            tmp.write(f\"{species},{threshold:.2f},{prediction_above_threshold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anurofeca_richardsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anurofeca_richardsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anurofeca_richardsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anurofeca_richardsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anurofeca_richardsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unidentified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110000 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  151  152  153  154  155  156  157  \\\n",
       "0     4  3  4  4  2  1  1  2  2  3  ...    0    0    0    0    0    0    0   \n",
       "1     4  3  4  4  2  1  1  2  2  3  ...    3    4    0    0    0    0    0   \n",
       "2     4  3  4  4  2  1  1  2  2  3  ...    0    0    0    0    0    0    0   \n",
       "3     4  3  4  4  2  1  1  2  2  3  ...    4    0    0    0    0    0    0   \n",
       "4     4  3  4  4  2  1  1  2  2  3  ...    3    4    0    0    0    0    0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9995  4  3  4  4  2  1  1  2  2  3  ...    3    1    3    4    0    0    0   \n",
       "9996  4  3  4  4  2  1  1  2  2  3  ...    4    3    1    3    1    3    4   \n",
       "9997  4  3  4  4  2  1  1  2  2  3  ...    1    3    1    3    4    0    0   \n",
       "9998  4  3  4  4  2  1  1  2  2  3  ...    4    0    0    0    0    0    0   \n",
       "9999  4  3  4  4  2  1  1  2  2  3  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "      158  159                  160  \n",
       "0       0    0  Anurofeca_richardsi  \n",
       "1       0    0  Anurofeca_richardsi  \n",
       "2       0    0  Anurofeca_richardsi  \n",
       "3       0    0  Anurofeca_richardsi  \n",
       "4       0    0  Anurofeca_richardsi  \n",
       "...   ...  ...                  ...  \n",
       "9995    0    0         unidentified  \n",
       "9996    0    0         unidentified  \n",
       "9997    0    0         unidentified  \n",
       "9998    0    0         unidentified  \n",
       "9999    0    0         unidentified  \n",
       "\n",
       "[110000 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger les données simulées d'espèces identifiées\n",
    "simulated = pd.read_csv(filepath_or_buffer=SIMULATED_FILE)\n",
    "\n",
    "# Charger les données simulées d'espèces non identifiées\n",
    "unindentified = pd.read_csv(filepath_or_buffer=UNIDENTIFIED_FILE)\n",
    "\n",
    "# Concaténer les deux ensembles de données (espèces identifiées et non identifiées) verticalement (axis=0)\n",
    "datas = pd.concat(objs=[simulated, unindentified], axis=0)\n",
    "\n",
    "# Afficher les données concaténées\n",
    "display(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des labels et splitting des données en ensemble d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des caractéristiques (features) et de la cible (target) à partir du DataFrame 'datas'\n",
    "features, target = datas.iloc[:, :-1], datas.iloc[:, -1]\n",
    "\n",
    "# Initialisation et ajustement d'un encodeur d'étiquettes (LabelEncoder) sur la cible (target)\n",
    "encoder = LabelEncoder().fit(y=target)\n",
    "\n",
    "# Transformation des étiquettes de la cible en valeurs numériques à l'aide de l'encodeur\n",
    "target = encoder.transform(y=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle XGBoost et test sur des données simulées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10000\n",
      "           1       1.00      1.00      1.00     10000\n",
      "           2       1.00      1.00      1.00     10000\n",
      "           3       1.00      1.00      1.00     10000\n",
      "           4       1.00      1.00      1.00     10000\n",
      "           5       0.97      0.99      0.98     10000\n",
      "           6       0.99      0.97      0.98     10000\n",
      "           7       1.00      1.00      1.00     10000\n",
      "           8       1.00      1.00      1.00     10000\n",
      "           9       1.00      1.00      1.00     10000\n",
      "          10       1.00      1.00      1.00     10000\n",
      "\n",
      "    accuracy                           1.00    110000\n",
      "   macro avg       1.00      1.00      1.00    110000\n",
      "weighted avg       1.00      1.00      1.00    110000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialisation et ajustement d'un modèle XGBoost Classifier sur l'ensemble d'entraînement\n",
    "with open(file=CLF_FILE, mode=\"rb\") as model:\n",
    "    xgb_model: xgb_.XGBClassifier = pk.load(file=model)\n",
    "\n",
    "# Prédictions sur l'ensemble de test à l'aide du modèle entraîné\n",
    "y_pred = xgb_model.predict(X=features)\n",
    "\n",
    "# Affichage du rapport de classification, fournissant des métriques d'évaluation du modèle\n",
    "print(classification_report(y_true=target, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur des données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse pour chaque barcode\n",
    "for number in BARCODES:\n",
    "    process_barcode(number=number, xgb_model=xgb_model, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
